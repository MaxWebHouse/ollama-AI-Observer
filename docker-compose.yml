
services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama_service # Good for user if they need to exec into it manually
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    restart: unless-stopped

  observer_app:
    build:
      context: .
      dockerfile: Dockerfile

    container_name: observer_app_and_proxy
    ports:
      - "8080:80"    # Web UI (Nginx)
      - "3838:3838"  # Proxy API (Python HTTPS)
    restart: unless-stopped
    depends_on:
      - ollama # Default: depends on the bundled ollama service
    environment:
      # These allow overriding the Ollama connection if the user wants to.
      # Defaults in Python code are "ollama" and "11434", which work with the bundled service.
      - OLLAMA_SERVICE_HOST=${OLLAMA_HOST_OVERRIDE:-ollama}
      - OLLAMA_SERVICE_PORT=${OLLAMA_PORT_OVERRIDE:-11434}
    # Mount Docker socket only if /exec feature is active and desired
    # This makes the /exec feature tied to using the bundled Ollama.
    # If OLLAMA_HOST_OVERRIDE is set to something else, /exec might not make sense or work.
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

volumes:
  ollama_data: {}
